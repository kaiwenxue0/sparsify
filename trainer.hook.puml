@startuml
|Trainer|
:for 每个目标 hookpoint, 注册 forward_hook 到 Module;
repeat
  :获取 batch x，调用 model(x) 前向;
  |Model|
  repeat
  :数据流经被 hook 的 Module;
  :自动触发 forward_hook 回调;
  |Trainer hook function|
  :解包 inputs/outputs（处理 tuple）;
  :根据 Module 找到对应 name;
  if (分布式且需要all_gather) then (是)
    |Torch Distributed|
    :all_gather outputs（如有transcode也all_gather inputs）;
    |Trainer hook function|
    :如果该 module 不属于本 rank，直接返回;
  endif
  :outputs, inputs 展平为 (batch*seq, dim);
  :取出对应 SparseCoder;
  if (global_step == 0 且非finetune) then (首次迭代初始化)
    if (transcode) then (是)
      : <color:red>均值归一初始化 encoder.bias</color>;
    endif
    :<color:red>均值归一初始化 decoder.bias</color>;
  endif
  if (autoencoder 且 normalize_decoder) then (是)
    :归一化 decoder 权重;
  endif
  :调用 SparseCoder/SAE.forward(inputs, outputs,...);
  |SparseCoder|
  :encode → top-k latent 及 index;
  :decode → SAE 重构输出;
  :计算残差 e 及 FVU;
  :如需 auxk_loss 则筛 dead feature 求 loss;
  :如需 multi_topk_fvu 计算额外 FVU;
  :返回 ForwardOutput(sae_out, top_acts, indices, fvu, auxk_loss, multi_topk_fvu);
  |Trainer hook function|
  :did_fire[name] 标记已激活 latent;
  :all_reduce did_fire （如分布式）;
  if (loss_fn 为 ce/kl) then (是)
    :reshape sae_out 替换模型输出，return;
  else
    :累加fvu、auxk_loss、multi_topk_fvu;
    :loss = fvu + auxk_loss + multi_topk_fvu/8;
    :loss / acc_steps backward();
  endif
  |Model|
  :继续模型前向;
repeat while (所有被 hook 的 Module 触发完)
|Trainer|
:batch 处理完毕，移除所有 hook handle;
repeat while (epoch未结束)
@enduml
